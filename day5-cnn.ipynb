{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recent-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "path_1 = './img/jjajang'\n",
    "path_2 = './img/tangsu'\n",
    "path_t = './data/tangjja'\n",
    "\n",
    "id = 0\n",
    "\n",
    "# 파일 이름 일괄 변경\n",
    "for (path, dirs, files) in os.walk(path_1):\n",
    "    for filename in files:\n",
    "        newname = '0_{}.jpg'.format(id)\n",
    "        id+=1\n",
    "        os.rename(path_1 + '/' + filename, path_t + '/' + newname)\n",
    "\n",
    "for (path, dirs, files) in os.walk(path_2):\n",
    "    for filename in files:\n",
    "        newname = '1_{}.jpg'.format(id)\n",
    "        id+=1\n",
    "        os.rename(path_2 + '/' + filename, path_t + '/' + newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "charged-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-yvyj7qlp/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-yvyj7qlp/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# path_t = './data/tangjja'\n",
    "\n",
    "# 파일 사이즈 일괄 변경\n",
    "IMG_SIZE = 32\n",
    "\n",
    "for filename in os.listdir(path_t):\n",
    "    try:\n",
    "        path = path_t + '/' + filename\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img1 = cv2.resize(img, dsize = (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite('./data/tangjja_resize/' + '/' + filename, img1)\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promotional-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "max_num_datas = 100\n",
    "test_num_datas = 20\n",
    "num_classes = 4\n",
    "num_datas_list = np.zeros(num_classes)\n",
    "\n",
    "img_train = './data/cifar_train/'\n",
    "img_test = './data/cifar_test/'\n",
    "\n",
    "id = 0\n",
    "\n",
    "for x, y in zip(x_train, y_train):\n",
    "    if np.sum(num_datas_list) > (max_num_datas + test_num_datas)*len(num_datas_list):\n",
    "        break\n",
    "    label = y[0]\n",
    "    if label >= num_classes:\n",
    "        continue\n",
    "        \n",
    "    #download training data\n",
    "    if num_datas_list[label] < max_num_datas:\n",
    "        num_datas_list[label] += 1\n",
    "        \n",
    "        img_path = os.path.join(img_train, '{}_{}.jpg'.format(label, id))\n",
    "        id += 1\n",
    "        img = Image.fromarray(x)\n",
    "        img.save(img_path)\n",
    "        \n",
    "    #download tesing data\n",
    "    if num_datas_list[label] >= max_num_datas and num_datas_list[label] < (max_num_datas*test_num_datas):\n",
    "        num_datas_list[label] += 1\n",
    "        \n",
    "        img_path = os.path.join(img_test, '{}_{}.jpg'.format(label, id))\n",
    "        id += 1\n",
    "        img = Image.fromarray(x)\n",
    "        img.save(img_path)\n",
    "        \n",
    "    if num_datas_list[label] >= max_num_datas + test_num_datas:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "linear-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "shape of datas: (442, 32, 32, 3)\tshape of labels: (442,)\n",
      "shape of datas: (122, 32, 32, 3)\tshape of labels: (122,)\n",
      "Tensor(\"conv2d/Relu:0\", shape=(?, 28, 28, 20), dtype=float32)\n",
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 20), dtype=float32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 11, 11, 40), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 5, 5, 40), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 1000), dtype=float32)\n",
      "Tensor(\"dense/Relu:0\", shape=(?, 400), dtype=float32)\n",
      "Tensor(\"dropout/Identity:0\", shape=(?, 400), dtype=float32)\n",
      "Tensor(\"dense_1/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "testing\n",
      "INFO:tensorflow:Restoring parameters from ./models/cifar_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/pooling.py:310: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:268: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  warnings.warn('`tf.layers.dropout` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ./models/cifar_model loaded\n",
      "./data/cifar_test/1_163.jpg\tcar => car\n",
      "./data/cifar_test/1_188.jpg\tcar => car\n",
      "./data/cifar_test/1_361.jpg\tcar => car\n",
      "./data/cifar_test/1_201.jpg\tcar => car\n",
      "./data/cifar_test/1_215.jpg\tcar => car\n",
      "./data/cifar_test/3_462.jpg\tcat => cat\n",
      "./data/cifar_test/1_374.jpg\tcar => airplane\n",
      "./data/cifar_test/1_148.jpg\tcar => car\n",
      "./data/cifar_test/0_398.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_410.jpg\tcar => car\n",
      "./data/cifar_test/2_458.jpg\tbird => car\n",
      "./data/cifar_test/3_461.jpg\tcat => cat\n",
      "./data/cifar_test/3_475.jpg\tcat => cat\n",
      "./data/cifar_test/3_460.jpg\tcat => bird\n",
      "./data/cifar_test/3_448.jpg\tcat => cat\n",
      "./data/cifar_test/0_206.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_465.jpg\tbird => airplane\n",
      "./data/cifar_test/1_203.jpg\tcar => car\n",
      "./data/cifar_test/1_388.jpg\tcar => car\n",
      "./data/cifar_test/1_405.jpg\tcar => car\n",
      "./data/cifar_test/0_400.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_414.jpg\tairplane => cat\n",
      "./data/cifar_test/1_161.jpg\tcar => car\n",
      "./data/cifar_test/1_165.jpg\tcar => car\n",
      "./data/cifar_test/1_415.jpg\tcar => airplane\n",
      "./data/cifar_test/1_207.jpg\tcar => car\n",
      "./data/cifar_test/0_216.jpg\tairplane => airplane\n",
      "./data/cifar_test/3_471.jpg\tcat => cat\n",
      "./data/cifar_test/2_474.jpg\tbird => cat\n",
      "./data/cifar_test/1_428.jpg\tcar => car\n",
      "./data/cifar_test/1_416.jpg\tcar => car\n",
      "./data/cifar_test/1_402.jpg\tcar => cat\n",
      "./data/cifar_test/1_204.jpg\tcar => car\n",
      "./data/cifar_test/1_210.jpg\tcar => car\n",
      "./data/cifar_test/1_238.jpg\tcar => car\n",
      "./data/cifar_test/0_229.jpg\tairplane => airplane\n",
      "./data/cifar_test/3_473.jpg\tcat => car\n",
      "./data/cifar_test/0_228.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_200.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_463.jpg\tbird => airplane\n",
      "./data/cifar_test/1_359.jpg\tcar => car\n",
      "./data/cifar_test/1_365.jpg\tcar => cat\n",
      "./data/cifar_test/2_411.jpg\tbird => airplane\n",
      "./data/cifar_test/0_476.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_412.jpg\tbird => bird\n",
      "./data/cifar_test/1_472.jpg\tcar => cat\n",
      "./data/cifar_test/3_239.jpg\tcat => cat\n",
      "./data/cifar_test/0_477.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_467.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_417.jpg\tbird => bird\n",
      "./data/cifar_test/0_466.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_464.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_470.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_449.jpg\tcar => car\n",
      "./data/cifar_test/3_438.jpg\tcat => cat\n",
      "./data/cifar_test/3_439.jpg\tcat => bird\n",
      "./data/cifar_test/0_459.jpg\tairplane => car\n",
      "./data/cifar_test/1_445.jpg\tcar => car\n",
      "./data/cifar_test/2_223.jpg\tbird => bird\n",
      "./data/cifar_test/2_222.jpg\tbird => bird\n",
      "./data/cifar_test/1_444.jpg\tcar => cat\n",
      "./data/cifar_test/1_478.jpg\tcar => car\n",
      "./data/cifar_test/3_227.jpg\tcat => cat\n",
      "./data/cifar_test/0_455.jpg\tairplane => airplane\n",
      "./data/cifar_test/0_443.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_136.jpg\tcar => car\n",
      "./data/cifar_test/3_437.jpg\tcat => bird\n",
      "./data/cifar_test/2_427.jpg\tbird => cat\n",
      "./data/cifar_test/2_221.jpg\tbird => bird\n",
      "./data/cifar_test/0_446.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_231.jpg\tbird => bird\n",
      "./data/cifar_test/2_423.jpg\tbird => cat\n",
      "./data/cifar_test/3_432.jpg\tcat => car\n",
      "./data/cifar_test/2_230.jpg\tbird => bird\n",
      "./data/cifar_test/0_479.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_468.jpg\tcar => car\n",
      "./data/cifar_test/2_232.jpg\tbird => bird\n",
      "./data/cifar_test/2_434.jpg\tbird => airplane\n",
      "./data/cifar_test/3_431.jpg\tcat => cat\n",
      "./data/cifar_test/2_409.jpg\tbird => bird\n",
      "./data/cifar_test/2_435.jpg\tbird => bird\n",
      "./data/cifar_test/1_441.jpg\tcar => car\n",
      "./data/cifar_test/1_156.jpg\tcar => car\n",
      "./data/cifar_test/1_181.jpg\tcar => car\n",
      "./data/cifar_test/1_397.jpg\tcar => car\n",
      "./data/cifar_test/2_240.jpg\tbird => bird\n",
      "./data/cifar_test/1_383.jpg\tcar => cat\n",
      "./data/cifar_test/2_452.jpg\tbird => cat\n",
      "./data/cifar_test/3_457.jpg\tcat => cat\n",
      "./data/cifar_test/3_456.jpg\tcat => cat\n",
      "./data/cifar_test/1_235.jpg\tcar => car\n",
      "./data/cifar_test/1_396.jpg\tcar => car\n",
      "./data/cifar_test/1_433.jpg\tcar => car\n",
      "./data/cifar_test/0_393.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_180.jpg\tcar => car\n",
      "./data/cifar_test/0_422.jpg\tairplane => car\n",
      "./data/cifar_test/1_419.jpg\tcar => bird\n",
      "./data/cifar_test/1_237.jpg\tcar => car\n",
      "./data/cifar_test/2_451.jpg\tbird => airplane\n",
      "./data/cifar_test/1_236.jpg\tcar => car\n",
      "./data/cifar_test/1_395.jpg\tcar => airplane\n",
      "./data/cifar_test/0_425.jpg\tairplane => airplane\n",
      "./data/cifar_test/1_193.jpg\tcar => car\n",
      "./data/cifar_test/2_454.jpg\tbird => cat\n",
      "./data/cifar_test/2_440.jpg\tbird => airplane\n",
      "./data/cifar_test/3_450.jpg\tcat => airplane\n",
      "./data/cifar_test/2_469.jpg\tbird => bird\n",
      "./data/cifar_test/1_233.jpg\tcar => car\n",
      "./data/cifar_test/1_384.jpg\tcar => car\n",
      "./data/cifar_test/1_421.jpg\tcar => cat\n",
      "./data/cifar_test/1_151.jpg\tcar => car\n",
      "./data/cifar_test/1_379.jpg\tcar => car\n",
      "./data/cifar_test/2_480.jpg\tbird => airplane\n",
      "./data/cifar_test/0_234.jpg\tairplane => airplane\n",
      "./data/cifar_test/3_447.jpg\tcat => cat\n",
      "./data/cifar_test/3_453.jpg\tcat => cat\n",
      "./data/cifar_test/0_209.jpg\tairplane => airplane\n",
      "./data/cifar_test/2_442.jpg\tbird => bird\n",
      "./data/cifar_test/1_218.jpg\tcar => car\n",
      "./data/cifar_test/1_224.jpg\tcar => car\n",
      "./data/cifar_test/1_436.jpg\tcar => car\n",
      "./data/cifar_test/1_191.jpg\tcar => car\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "data_dir = './data/cifar_train/' # 트레이닝 이미지 저장 폴더\n",
    "data_dirt = './data/cifar_test/' # 테스트 이미지 저장 폴더\n",
    "\n",
    "#train = True  # 트레이닝 or 테스트 선택하기\n",
    "train = False  # 트레이닝 or 테스트 선택하기\n",
    "model_path = './models/cifar_model' #model 저장경로\n",
    "\n",
    "# 이미지 폴더로부터 이미지들을 load하고 numpy에 저장한다.\n",
    "# 이미지 filename이 1_40.jpg 일 때, Lable=1 이다.\n",
    "def read_data(data_dir):\n",
    "    datas = []\n",
    "    labels = []\n",
    "    fpaths = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        fpath = os.path.join(data_dir, fname)\n",
    "        fpaths.append(fpath)\n",
    "        image = Image.open(fpath)\n",
    "        data = np.array(image) / 255.0\n",
    "        label = int(fname.split(\"_\")[0])\n",
    "        datas.append(data)\n",
    "        labels.append(label)\n",
    "\n",
    "    datas = np.array(datas)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(\"shape of datas: {}\\tshape of labels: {}\".format(datas.shape, labels.shape))\n",
    "    return fpaths, datas, labels\n",
    "\n",
    "fpaths, datas, labels = read_data(data_dir) #트레이닝 데이터\n",
    "fpathst, datast, labelst = read_data(data_dirt) #테스트 데이터\n",
    "\n",
    "# 이미지 class 개수\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "# Placeholder에 input데이터와 label를 저장한다.\n",
    "datas_placeholder = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "labels_placeholder = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Placeholder에 DropOut 파라미터를 저장한다.트레이닝할 때 0.25，테스트 할 때 0.\n",
    "dropout_placeholdr = tf.placeholder(tf.float32)\n",
    "\n",
    "# Conv Layer0: input=32x32x3, filters=20, kernal_size=5，stride=1x1\n",
    "#conv0 = tf.keras.layers.Conv2D(datas_placeholder, 20, 5, activation=tf.nn.relu)\n",
    "conv0 = tf.layers.conv2d(datas_placeholder, 20, 5, activation=tf.nn.relu)\n",
    "\n",
    "print(conv0)\n",
    "# output size= [(W - F + 2P)/S] +1 = (32-5)/1+1 =28\n",
    "# Tensor(\"conv2d/Relu:0\", shape=(?, 28, 28, 20), dtype=float32)\n",
    "\n",
    "# max-pooling0: input=28x28x20, pooling size=2x2，stride=2x2\n",
    "pool0 = tf.layers.max_pooling2d(conv0, [2, 2], [2, 2])\n",
    "print(pool0)\n",
    "# output size= W = [(W - F )/S] +1 = [(28-2)/2]+1 =14\n",
    "# Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 20), dtype=float32)\n",
    "\n",
    "# Conv Layer1: input=14x14x20, filters=40, kernal_size=4，stride=1x1\n",
    "conv1 = tf.layers.conv2d(pool0, 40, 4, activation=tf.nn.relu)\n",
    "print(conv1)\n",
    "# output size= [(W - F + 2P)/S] +1 = (14-4)/1+1 =11\n",
    "# Tensor(\"conv2d_1/Relu:0\", shape=(?, 11, 11, 40), dtype=float32)\n",
    "\n",
    "# max-pooling1: input=11x11x40, pooling size=2x2，stride=2x2\n",
    "pool1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n",
    "print(pool1)\n",
    "# output size= W = [(W - F )/S] +1 = [(11-2)/2]+1 =5.5\n",
    "# Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 5, 5, 40), dtype=float32)\n",
    "\n",
    "# 3-D vector을 1-D vector로 변환한다.\n",
    "flatten = tf.layers.flatten(pool1)\n",
    "print(flatten)\n",
    "# output size=5x5x40=1000\n",
    "# Tensor(\"flatten/Reshape:0\", shape=(?, 1000), dtype=float32)\n",
    "\n",
    "# fully-connected layer\n",
    "fc = tf.layers.dense(flatten, 400, activation=tf.nn.relu)\n",
    "print(fc)\n",
    "# Tensor(\"dense/Relu:0\", shape=(?, 400), dtype=float32)\n",
    "\n",
    "# DropOut를 추가하여 overfitting을 방지한다.\n",
    "dropout_fc = tf.layers.dropout(fc, dropout_placeholdr)\n",
    "print(dropout_fc)\n",
    "# Tensor(\"dropout/Identity:0\", shape=(?, 400), dtype=float32)\n",
    "\n",
    "# output=4개 class\n",
    "logits = tf.layers.dense(dropout_fc, num_classes)\n",
    "print(logits)\n",
    "#Tensor(\"dense_1/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
    "\n",
    "predicted_labels = tf.arg_max(logits, 1)\n",
    "\n",
    "\n",
    "# loss를 정의한다.\n",
    "losses = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(labels_placeholder, num_classes), #실제 label\n",
    "    logits=logits #트레이닝 output label\n",
    ")\n",
    "\n",
    "mean_loss = tf.reduce_mean(losses)\n",
    "\n",
    "# optimizer를 정의한다.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(losses)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    if train:\n",
    "        print(\"training\")\n",
    "        # 트레이닝하기전 initializing 한다.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # placeholder에 데이터를 넣는다.\n",
    "        train_feed_dict = {\n",
    "            datas_placeholder: datas,\n",
    "            labels_placeholder: labels,\n",
    "            dropout_placeholdr: 0.25\n",
    "        }\n",
    "        for step in range(1000):\n",
    "            _, mean_loss_val = sess.run([optimizer, mean_loss], feed_dict=train_feed_dict)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(\"step = {}\\tmean loss = {}\".format(step, mean_loss_val))\n",
    "        saver.save(sess, model_path)\n",
    "        print(\"training done! saved in {}\".format(model_path))\n",
    "    else:\n",
    "        print(\"testing\")\n",
    "        # 트레이닝한 model을 불러온다\n",
    "        saver.restore(sess, model_path)\n",
    "        print(\"from {} loaded\".format(model_path))\n",
    "        # label의 각 의미\n",
    "        label_name_dict = {\n",
    "            0: \"airplane\",\n",
    "            1: \"car\",\n",
    "            2: \"bird\",\n",
    "            3: \"cat\"\n",
    "        }\n",
    "        # placeholder에 데이터를 넣는다.\n",
    "        test_feed_dict = {\n",
    "            datas_placeholder: datast,\n",
    "            labels_placeholder: labelst,\n",
    "            dropout_placeholdr: 0\n",
    "        }\n",
    "        predicted_labels_val = sess.run(predicted_labels, feed_dict=test_feed_dict)\n",
    "        # 테스트결과와 실제결과를 비교한다.\n",
    "        for fpathst, real_label, predicted_label in zip(fpathst, labelst, predicted_labels_val):\n",
    "            real_label_name = label_name_dict[real_label]\n",
    "            predicted_label_name = label_name_dict[predicted_label]\n",
    "            print(\"{}\\t{} => {}\".format(fpathst, real_label_name, predicted_label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "shape of datas: (80, 32, 32, 3)\tshape of labels: (80,)\n",
      "shape of datas: (20, 32, 32, 3)\tshape of labels: (20,)\n",
      "2\n",
      "Tensor(\"conv2d/Relu:0\", shape=(?, 28, 28, 20), dtype=float32)\n",
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 20), dtype=float32)\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 11, 11, 40), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 5, 5, 40), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 1000), dtype=float32)\n",
      "Tensor(\"dense/Relu:0\", shape=(?, 400), dtype=float32)\n",
      "Tensor(\"dropout/Identity:0\", shape=(?, 400), dtype=float32)\n",
      "Tensor(\"dense_1/BiasAdd:0\", shape=(?, 2), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "testing\n",
      "INFO:tensorflow:Restoring parameters from ./models/tangjja.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/pooling.py:310: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/Users/keunmo/Workspace/projects/chatbot/cbvenv/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:268: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  warnings.warn('`tf.layers.dropout` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ./models/tangjja.model loaded\n",
      "./data/tangjja_test/1_98.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_99.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/0_47.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_46.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_44.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_45.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_41.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_40.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_42.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_43.jpg\tjjajang => tangsu\n",
      "./data/tangjja_test/0_48.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/0_49.jpg\tjjajang => jjajang\n",
      "./data/tangjja_test/1_92.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_93.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_91.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_90.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_94.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_95.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_97.jpg\ttangsu => tangsu\n",
      "./data/tangjja_test/1_96.jpg\ttangsu => tangsu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "data_dir = './data/tangjja_train/' # 트레이닝 이미지 저장 폴더\n",
    "data_dirt = './data/tangjja_test/' # 테스트 이미지 저장 폴더\n",
    "\n",
    "#train = True  # 트레이닝 or 테스트 선택하기\n",
    "train = False  # 트레이닝 or 테스트 선택하기\n",
    "model_path = './models/tangjja.model' #model 저장경로\n",
    "\n",
    "# 이미지 폴더로부터 이미지들을 load하고 numpy에 저장한다.\n",
    "# 이미지 filename이 1_40.jpg 일 때, Lable=1 이다.\n",
    "def read_data(data_dir):\n",
    "    datas = []\n",
    "    labels = []\n",
    "    fpaths = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        fpath = os.path.join(data_dir, fname)\n",
    "        fpaths.append(fpath)\n",
    "        image = Image.open(fpath)\n",
    "        data = np.array(image) / 255.0\n",
    "        label = int(fname.split(\"_\")[0])\n",
    "        datas.append(data)\n",
    "        labels.append(label)\n",
    "\n",
    "    datas = np.array(datas)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(\"shape of datas: {}\\tshape of labels: {}\".format(datas.shape, labels.shape))\n",
    "    return fpaths, datas, labels\n",
    "\n",
    "fpaths, datas, labels = read_data(data_dir) #트레이닝 데이터\n",
    "fpathst, datast, labelst = read_data(data_dirt) #테스트 데이터\n",
    "\n",
    "# 이미지 class 개수\n",
    "num_classes = len(set(labels))\n",
    "print(num_classes)\n",
    "\n",
    "# Placeholder에 input데이터와 label를 저장한다.\n",
    "datas_placeholder = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "labels_placeholder = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Placeholder에 DropOut 파라미터를 저장한다.트레이닝할 때 0.25，테스트 할 때 0.\n",
    "dropout_placeholdr = tf.placeholder(tf.float32)\n",
    "\n",
    "# Conv Layer0: input=32x32x3, filters=20, kernal_size=5，stride=1x1\n",
    "#conv0 = tf.keras.layers.Conv2D(datas_placeholder, 20, 5, activation=tf.nn.relu)\n",
    "conv0 = tf.layers.conv2d(datas_placeholder, 20, 5, activation=tf.nn.relu)\n",
    "\n",
    "print(conv0)\n",
    "# output size= [(W - F + 2P)/S] +1 = (32-5)/1+1 =28\n",
    "# Tensor(\"conv2d/Relu:0\", shape=(?, 28, 28, 20), dtype=float32)\n",
    "\n",
    "# max-pooling0: input=28x28x20, pooling size=2x2，stride=2x2\n",
    "pool0 = tf.layers.max_pooling2d(conv0, [2, 2], [2, 2])\n",
    "print(pool0)\n",
    "# output size= W = [(W - F )/S] +1 = [(28-2)/2]+1 =14\n",
    "# Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 20), dtype=float32)\n",
    "\n",
    "# Conv Layer1: input=14x14x20, filters=40, kernal_size=4，stride=1x1\n",
    "conv1 = tf.layers.conv2d(pool0, 40, 4, activation=tf.nn.relu)\n",
    "print(conv1)\n",
    "# output size= [(W - F + 2P)/S] +1 = (14-4)/1+1 =11\n",
    "# Tensor(\"conv2d_1/Relu:0\", shape=(?, 11, 11, 40), dtype=float32)\n",
    "\n",
    "# max-pooling1: input=11x11x40, pooling size=2x2，stride=2x2\n",
    "pool1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n",
    "print(pool1)\n",
    "# output size= W = [(W - F )/S] +1 = [(11-2)/2]+1 =5.5\n",
    "# Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 5, 5, 40), dtype=float32)\n",
    "\n",
    "# 3-D vector을 1-D vector로 변환한다.\n",
    "flatten = tf.layers.flatten(pool1)\n",
    "print(flatten)\n",
    "# output size=5x5x40=1000\n",
    "# Tensor(\"flatten/Reshape:0\", shape=(?, 1000), dtype=float32)\n",
    "\n",
    "# fully-connected layer\n",
    "fc = tf.layers.dense(flatten, 400, activation=tf.nn.relu)\n",
    "print(fc)\n",
    "# Tensor(\"dense/Relu:0\", shape=(?, 400), dtype=float32)\n",
    "\n",
    "# DropOut를 추가하여 overfitting을 방지한다.\n",
    "dropout_fc = tf.layers.dropout(fc, dropout_placeholdr)\n",
    "print(dropout_fc)\n",
    "# Tensor(\"dropout/Identity:0\", shape=(?, 400), dtype=float32)\n",
    "\n",
    "# output=4개 class\n",
    "logits = tf.layers.dense(dropout_fc, num_classes)\n",
    "print(logits)\n",
    "#Tensor(\"dense_1/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
    "\n",
    "predicted_labels = tf.arg_max(logits, 1)\n",
    "\n",
    "\n",
    "# loss를 정의한다.\n",
    "losses = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(labels_placeholder, num_classes), #실제 label\n",
    "    logits=logits #트레이닝 output label\n",
    ")\n",
    "\n",
    "mean_loss = tf.reduce_mean(losses)\n",
    "\n",
    "# optimizer를 정의한다.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(losses)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    if train:\n",
    "        print(\"training\")\n",
    "        # 트레이닝하기전 initializing 한다.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # placeholder에 데이터를 넣는다.\n",
    "        train_feed_dict = {\n",
    "            datas_placeholder: datas,\n",
    "            labels_placeholder: labels,\n",
    "            dropout_placeholdr: 0.25\n",
    "        }\n",
    "        for step in range(300):\n",
    "            _, mean_loss_val = sess.run([optimizer, mean_loss], feed_dict=train_feed_dict)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(\"step = {}\\tmean loss = {}\".format(step, mean_loss_val))\n",
    "        saver.save(sess, model_path)\n",
    "        print(\"training done! saved in {}\".format(model_path))\n",
    "    else:\n",
    "        print(\"testing\")\n",
    "        # 트레이닝한 model을 불러온다\n",
    "        saver.restore(sess, model_path)\n",
    "        print(\"from {} loaded\".format(model_path))\n",
    "        # label의 각 의미\n",
    "        label_name_dict = {\n",
    "            0: \"jjajang\",\n",
    "            1: \"tangsu\"\n",
    "        }\n",
    "        # placeholder에 데이터를 넣는다.\n",
    "        test_feed_dict = {\n",
    "            datas_placeholder: datast,\n",
    "            labels_placeholder: labelst,\n",
    "            dropout_placeholdr: 0\n",
    "        }\n",
    "        predicted_labels_val = sess.run(predicted_labels, feed_dict=test_feed_dict)\n",
    "        # 테스트결과와 실제결과를 비교한다.\n",
    "        for fpathst, real_label, predicted_label in zip(fpathst, labelst, predicted_labels_val):\n",
    "            real_label_name = label_name_dict[real_label]\n",
    "            predicted_label_name = label_name_dict[predicted_label]\n",
    "            print(\"{}\\t{} => {}\".format(fpathst, real_label_name, predicted_label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-demographic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
